{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks in hls4ml\n",
    "\n",
    "In this notebook you will learn how to train a pruned and quantized convolutional neural network (CNN) and deploy it using hls4ml. For this exercise, we will use the Street View House Numbers (SVHN) Dataset (http://ufldl.stanford.edu/housenumbers/).\n",
    "\n",
    "The SVHN dataset consists of real-world images of house numbers extracted from Google Street View images. The format is similar to that of the MNIST dataset, but is a much more challenging real-world problem, as illustrated by the examples shown below.\n",
    "\n",
    "All the images are in RGB format and have been cropped to 32x32 pixels. \n",
    "Unlike MNIST, more than one digit can be present in the same image and in these cases, the center digit is used to assign a label to the image.\n",
    "Each image can belong to one of 10 classes, corresponding to digits 0 through 9.\n",
    "\n",
    "![alt text](images/test.png \"SVHN examples from the test dataset\")\n",
    "\n",
    "The SVHN dataset consists of 73,257 images for training (and 531,131 extra samples that are easier to classify and can be used as additional training data) and 26,032 images for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with the neccessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the SVHN dataset using Tensorflow Dataset\n",
    "\n",
    "In this part we will fetch the trainining, validation and test dataset using Tensorflow Datasets (https://www.tensorflow.org/datasets). We will not use the 'extra' training in order to save time, but you could fetch it by adding `split='train[:90%]+extra'`. We will use the first 90% of the training data for training and the last 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PrefetchDataset shapes: ((32, 32, 3), ()), types: (tf.uint8, tf.int64)>\n"
     ]
    }
   ],
   "source": [
    "ds_train, info = tfds.load('svhn_cropped', split='train[:90%]', with_info=True, data_dir=\"/eos/home-t/thaarres/tensorflow_datasets/\", as_supervised=True)\n",
    "ds_test        = tfds.load('svhn_cropped', split='test', shuffle_files=True, data_dir=\"/eos/home-t/thaarres/tensorflow_datasets/\", as_supervised=True)\n",
    "ds_val         = tfds.load('svhn_cropped', split='train[-10%:]', shuffle_files=True, data_dir=\"/eos/home-t/thaarres/tensorflow_datasets/\", as_supervised=True)\n",
    "\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "print(ds_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use TensorFlow Dataset to prepare our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 73257 samples\n"
     ]
    }
   ],
   "source": [
    "def preprocess(image, label,nclasses=10):\n",
    "  image = tf.cast(image, tf.float32) / 255.\n",
    "  label = tf.one_hot(tf.squeeze(label), nclasses)\n",
    "  return image, label\n",
    "\n",
    "batch_size = 1024\n",
    "epochs = 30\n",
    "\n",
    "train = ds_train.map(preprocess) #Get dataset as image and one-hot encoded labels, divided by max RGB    \n",
    "train = train.repeat()\n",
    "train = train.batch(batch_size) # Prepare batches\n",
    "train = train.prefetch(AUTO) # Allows later elements to be prepared while the current element is being processed\n",
    "\n",
    "val = ds_val.map(preprocess)    \n",
    "val = val.batch(batch_size)\n",
    "val = val.prefetch(AUTO)\n",
    "  \n",
    "test  = ds_test.map(preprocess)\n",
    "test  = test.batch(batch_size)\n",
    "test  = test.prefetch(AUTO)\n",
    "  \n",
    "train_size = int(info.splits['train'].num_examples)\n",
    "\n",
    "print('Training on {} samples'.format(train_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model\n",
    "\n",
    "We then need to define a model. We want the lowest latency model possible and therefore limit the size per layer to be below 4096. The reason for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch      = int(train_size*0.9)  // batch_size #90% train, 10% validation in 10-fold xval\n",
    "eval_steps_per_epoch = int(train_size*0.1) //  batch_size\n",
    "\n",
    "LOSS        = tf.keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER   = tf.keras.optimizers.Adam(learning_rate=3E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True) \n",
    "model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "model.summary()\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

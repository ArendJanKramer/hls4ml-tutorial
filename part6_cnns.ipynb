{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks in hls4ml\n",
    "\n",
    "In this notebook you will learn how to train a pruned and quantized convolutional neural network (CNN) and deploy it using hls4ml. For this exercise, we will use the Street View House Numbers (SVHN) Dataset (http://ufldl.stanford.edu/housenumbers/).\n",
    "\n",
    "The SVHN dataset consists of real-world images of house numbers extracted from Google Street View images. The format is similar to that of the MNIST dataset, but is a much more challenging real-world problem, as illustrated by the examples shown below.\n",
    "\n",
    "All the images are in RGB format and have been cropped to 32x32 pixels. \n",
    "Unlike MNIST, more than one digit can be present in the same image and in these cases, the center digit is used to assign a label to the image.\n",
    "Each image can belong to one of 10 classes, corresponding to digits 0 through 9.\n",
    "\n",
    "![alt text](images/test.png \"SVHN examples from the test dataset\")\n",
    "\n",
    "The SVHN dataset consists of 73,257 images for training (and 531,131 extra samples that are easier to classify and can be used as additional training data) and 26,032 images for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start with the neccessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch the SVHN dataset using Tensorflow Dataset\n",
    "\n",
    "In this part we will fetch the trainining, validation and test dataset using Tensorflow Datasets (https://www.tensorflow.org/datasets). We will not use the 'extra' training in order to save time, but you could fetch it by adding `split='train[:90%]+extra'`. We will use the first 90% of the training data for training and the last 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on 73257 samples of input shape (32, 32, 3), belonging to 10 classes\n"
     ]
    }
   ],
   "source": [
    "ds_train, info = tfds.load('svhn_cropped', split='train[:90%]', with_info=True, as_supervised=True)\n",
    "ds_test        = tfds.load('svhn_cropped', split='test', shuffle_files=True, as_supervised=True)\n",
    "ds_val         = tfds.load('svhn_cropped', split='train[-10%:]', shuffle_files=True, as_supervised=True)\n",
    "\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "train_size  = int(info.splits['train'].num_examples)\n",
    "input_shape = info.features['image'].shape \n",
    "n_classes    = info.features['label'].num_classes \n",
    "\n",
    "print('Training on {} samples of input shape {}, belonging to {} classes'.format(train_size,input_shape,n_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use TensorFlow Dataset to prepare our datasets. We'll fetch the training dataset as tuples, and the test dataset as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label,nclasses=10):\n",
    "  image = tf.cast(image, tf.float32) / 255.\n",
    "  label = tf.one_hot(tf.squeeze(label), nclasses)\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test type = <class 'tensorflow.python.framework.ops.EagerTensor'> , X_test shape = (26032, 32, 32, 3) \n"
     ]
    }
   ],
   "source": [
    "batch_size = 1024\n",
    "epochs = 20\n",
    "\n",
    "train = ds_train.map(preprocess,n_classes) #Get dataset as image and one-hot encoded labels, divided by max RGB    \n",
    "train = train.repeat()\n",
    "train = train.batch(batch_size) # Prepare batches\n",
    "train = train.prefetch(AUTO) # Allows later elements to be prepared while the current element is being processed\n",
    "\n",
    "val = ds_val.map(preprocess,n_classes)    \n",
    "val = val.batch(batch_size)\n",
    "val = val.prefetch(AUTO)\n",
    "\n",
    "#For  testing, we get the full dataset as numpy arrays to have access to labels and images separately\n",
    "X_test, Y_test = tfds.as_numpy(tfds.load('svhn_cropped',split='test',batch_size=-1,as_supervised=True,))\n",
    "X_test, Y_test = preprocess(X_test, Y_test,nclasses=n_classes)\n",
    "print(\"X_test type = {} , X_test shape = {} \".format(type(X_test), X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the model\n",
    "\n",
    "We then need to define a model. For the lowest possible latency, each layer should have a maximum number of trainable parameters of 4096. This is due to fixed limits in the Vivado compiler, beyond which maximally unrolled (=parallel) compilation will fail. This will allow us to use `strategy = 'latency'` in the hls4ml part, rather than `strategy = 'resource'`, in turn resulting in lower latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding convolutional block 0 with N=16 filters\n",
      "Adding convolutional block 1 with N=16 filters\n",
      "Adding convolutional block 2 with N=24 filters\n",
      "Adding dense block 0 with N=42 neurons\n",
      "Adding dense block 1 with N=64 neurons\n",
      "Model: \"keras_baseline\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 30, 30, 16)        432       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 30, 30, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv_act_0 (Activation)      (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 13, 13, 16)        2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 13, 13, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv_act_1 (Activation)      (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (None, 4, 4, 24)          3456      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 4, 4, 24)          96        \n",
      "_________________________________________________________________\n",
      "conv_act_2 (Activation)      (None, 4, 4, 24)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 2, 2, 24)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_0 (Dense)              (None, 42)                4032      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 42)                168       \n",
      "_________________________________________________________________\n",
      "dense_act_0 (Activation)     (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                2688      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_act_1 (Activation)     (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_dense (Dense)         (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "output_softmax (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 14,222\n",
      "Trainable params: 13,892\n",
      "Non-trainable params: 330\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "filters_per_conv_layer = [16,16,24]\n",
    "neurons_per_dense_layer = [42,64]\n",
    "\n",
    "x = x_in = Input(input_shape)\n",
    "x = BatchNormalization()(x)\n",
    "for i,f in enumerate(filters_per_conv_layer):\n",
    "    print( ('Adding convolutional block {} with N={} filters').format(i,f) )\n",
    "    x = Conv2D(int(f), kernel_size=(3,3), strides=(1,1), kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "               name='conv_{}'.format(i))(x) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu',name='conv_act_%i'%i)(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "for i,n in enumerate(neurons_per_dense_layer):\n",
    "  print( ('Adding dense block {} with N={} neurons').format(i,n) )\n",
    "  x = Dense(n,kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001),name='dense_%i'%i, use_bias=False)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Activation('relu',name='dense_act_%i'%i)(x)\n",
    "x = Dense(int(n_classes),name='output_dense')(x)\n",
    "x_out = Activation('softmax',name='output_softmax')(x)\n",
    "model = Model(inputs=[x_in], outputs=[x_out], name='keras_baseline')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets check if this model can be implemented completely parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_0: 432\n",
      "conv_1: 2304\n",
      "conv_2: 3456\n",
      "dense_0: 4032\n",
      "dense_1: 2688\n",
      "output_dense: 640\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    if layer.__class__.__name__ in ['Conv2D', 'Dense']:\n",
    "        w = layer.get_weights()[0]\n",
    "        layersize = np.prod(w.shape)\n",
    "        print(\"{}: {}\".format(layer.name,layersize)) # 0 = weights, 1 = biases\n",
    "        if (layersize > 4096): # assuming that shape[0] is batch, i.e., 'None'\n",
    "           print(\"Layer {} is too large ({}), are you sure you want to train?\".format(layer.name,layersize))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! It's below the Vivado-enforced unroll limit of 4096.\n",
    "\n",
    "### Prune dense and covolutional layers\n",
    "Since we've seen in the previous notebooks that pruning can be done at no accuracy cost, let's prune the convolutional and dense layers to 50% sparsity, skipping the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "from tensorflow_model_optimization.sparsity import keras as sparsity\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
    "\n",
    "def pruneFunction(layer):\n",
    "    pruning_params = {'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.0,final_sparsity=0.50, begin_step=0, end_step=1000, frequency=50)}\n",
    "    if isinstance(layer, tf.keras.layers.Conv2D):\n",
    "      return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)\n",
    "    if isinstance(layer, tf.keras.layers.Dense) and layer.name!='output_dense':\n",
    "      return tfmot.sparsity.keras.prune_low_magnitude(layer, **pruning_params)  \n",
    "    return layer\n",
    "\n",
    "model_pruned = tf.keras.models.clone_model( model, clone_function=pruneFunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "\n",
    "We're now ready to train the model! We defined the batch size and n epochs above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N training steps per epoch is 64\n",
      "Epoch 1/30\n",
      "64/64 [==============================] - 27s 419ms/step - loss: 1.5542 - accuracy: 0.5200 - val_loss: 2.0396 - val_accuracy: 0.3206\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - 26s 409ms/step - loss: 0.7584 - accuracy: 0.8017 - val_loss: 1.4174 - val_accuracy: 0.5560\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - 26s 410ms/step - loss: 0.6115 - accuracy: 0.8445 - val_loss: 0.9593 - val_accuracy: 0.7181\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - 27s 419ms/step - loss: 0.5496 - accuracy: 0.8613 - val_loss: 0.7231 - val_accuracy: 0.8055\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - 27s 423ms/step - loss: 0.5083 - accuracy: 0.8738 - val_loss: 0.6291 - val_accuracy: 0.8342\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - 27s 423ms/step - loss: 0.4773 - accuracy: 0.8823 - val_loss: 0.5664 - val_accuracy: 0.8576\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - 27s 420ms/step - loss: 0.4562 - accuracy: 0.8874 - val_loss: 0.5319 - val_accuracy: 0.8695\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - 27s 430ms/step - loss: 0.4452 - accuracy: 0.8895 - val_loss: 0.5091 - val_accuracy: 0.8733\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - 27s 425ms/step - loss: 0.4280 - accuracy: 0.8942 - val_loss: 0.4891 - val_accuracy: 0.8765\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - 27s 417ms/step - loss: 0.4175 - accuracy: 0.8966 - val_loss: 0.4885 - val_accuracy: 0.8739\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - 27s 417ms/step - loss: 0.4038 - accuracy: 0.8998 - val_loss: 0.4805 - val_accuracy: 0.8778\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - 27s 426ms/step - loss: 0.3952 - accuracy: 0.9020 - val_loss: 0.4678 - val_accuracy: 0.8823\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - 26s 414ms/step - loss: 0.3879 - accuracy: 0.9041 - val_loss: 0.4705 - val_accuracy: 0.8808\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - 27s 426ms/step - loss: 0.3827 - accuracy: 0.9047 - val_loss: 0.4690 - val_accuracy: 0.8827\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - 27s 417ms/step - loss: 0.3791 - accuracy: 0.9056 - val_loss: 0.4670 - val_accuracy: 0.8822\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.3716 - accuracy: 0.9079 - val_loss: 0.4706 - val_accuracy: 0.8793\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - 25s 398ms/step - loss: 0.3661 - accuracy: 0.9090 - val_loss: 0.4727 - val_accuracy: 0.8784\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - 27s 422ms/step - loss: 0.3616 - accuracy: 0.9101 - val_loss: 0.4675 - val_accuracy: 0.8818\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - 27s 419ms/step - loss: 0.3567 - accuracy: 0.9114 - val_loss: 0.4658 - val_accuracy: 0.8830\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - 26s 408ms/step - loss: 0.3539 - accuracy: 0.9117 - val_loss: 0.4657 - val_accuracy: 0.8830\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - 27s 418ms/step - loss: 0.3510 - accuracy: 0.9126 - val_loss: 0.4642 - val_accuracy: 0.8851\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - 27s 420ms/step - loss: 0.3484 - accuracy: 0.9129 - val_loss: 0.4715 - val_accuracy: 0.8847\n",
      "Epoch 23/30\n",
      "64/64 [==============================] - 26s 410ms/step - loss: 0.3457 - accuracy: 0.9143 - val_loss: 0.4662 - val_accuracy: 0.8807\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - 27s 421ms/step - loss: 0.3434 - accuracy: 0.9140 - val_loss: 0.4665 - val_accuracy: 0.8841\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - 27s 425ms/step - loss: 0.3412 - accuracy: 0.9149 - val_loss: 0.4702 - val_accuracy: 0.8825\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.9157\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00030000000260770325.\n",
      "64/64 [==============================] - 28s 432ms/step - loss: 0.3386 - accuracy: 0.9157 - val_loss: 0.4727 - val_accuracy: 0.8799\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - 28s 436ms/step - loss: 0.3180 - accuracy: 0.9226 - val_loss: 0.4369 - val_accuracy: 0.8919\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - 28s 438ms/step - loss: 0.3086 - accuracy: 0.9261 - val_loss: 0.4359 - val_accuracy: 0.8915\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - 29s 450ms/step - loss: 0.3067 - accuracy: 0.9267 - val_loss: 0.4356 - val_accuracy: 0.8924\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - 28s 436ms/step - loss: 0.3055 - accuracy: 0.9269 - val_loss: 0.4360 - val_accuracy: 0.8919\n",
      "\n",
      " It took 13.721146750450135 minutes to train!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "steps_per_epoch      = int(train_size*0.9)  // batch_size #90% train, 10% validation in 10-fold xval\n",
    "eval_steps_per_epoch = int(train_size*0.1) //  batch_size\n",
    "\n",
    "print('N training steps per epoch is {}'.format(steps_per_epoch))\n",
    "\n",
    "LOSS        = tf.keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER   = tf.keras.optimizers.Adam(learning_rate=3E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True) \n",
    "model_pruned.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "            tf.keras.callbacks.ModelCheckpoint('pruned_cnn_model_best.h5',monitor=\"val_loss\",verbose=0,save_best_only=True), \n",
    "            tf.keras.callbacks.ModelCheckpoint('pruned_cnn_weights_best.h5',monitor=\"val_loss\",verbose=0,save_weights_only=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001, cooldown=2, min_lr=1E-6),\n",
    "            pruning_callbacks.UpdatePruningStep()\n",
    "            ]      \n",
    "\n",
    "start = time.time()\n",
    "history = model_pruned.fit(train,\n",
    "                      epochs =  epochs,\n",
    "                      validation_data = val,\n",
    "                      callbacks = callbacks,\n",
    "                      steps_per_epoch = steps_per_epoch,  \n",
    "                      verbose=1)     \n",
    "end = time.time()\n",
    "print('\\n It took {} minutes to train!\\n'.format( (end - start)/60.))\n",
    "\n",
    "model_pruned.load_weights('pruned_cnn_weights_best.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice the accuracy is lower than that in the hls4ml CNN paper (https://arxiv.org/abs/2101.05108) despite the model being the same. The reson for this is that we didn't use the ``extra`` training data in order to save time. If you want to futher optimize the network, increasing the training data is a good place to start. Enlarging the model architecture comes at a high latency/resource cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantization and the fused Conv2D+BatchNormalization layer in QKeras\n",
    "Let's now create a pruned an quantized model using QKeras. For this, we will use a fused Convolutional and BatchNormalization (BN) layer from QKeras, which will further speed up the implementation when we implement the model using hls4ml. \n",
    "There is currently no fused Dense+BatchNoralization layer available in QKeras, so we'll use Keras BatchNormalization when BN follows a Dense layer for now. We'll use the same precision everywhere, namely a bit width of 6 and 0 integer bits (this will be implemented as``<7,1>`` in hls4ml, due to the missing sign-bit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding fused QConv+BN block 0 with N=16 filters\n",
      "Adding fused QConv+BN block 1 with N=16 filters\n",
      "Adding fused QConv+BN block 2 with N=24 filters\n",
      "Adding QDense block 0 with N=42 neurons\n",
      "Adding QDense block 1 with N=64 neurons\n",
      "Model: \"qkeras\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 32, 32, 3)         12        \n",
      "_________________________________________________________________\n",
      "conv_0 (QConv2DBatchnorm)    (None, 30, 30, 16)        497       \n",
      "_________________________________________________________________\n",
      "conv_act_0 (QActivation)     (None, 30, 30, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 15, 15, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (QConv2DBatchnorm)    (None, 13, 13, 16)        2369      \n",
      "_________________________________________________________________\n",
      "conv_act_1 (QActivation)     (None, 13, 13, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv_2 (QConv2DBatchnorm)    (None, 4, 4, 24)          3553      \n",
      "_________________________________________________________________\n",
      "conv_act_2 (QActivation)     (None, 4, 4, 24)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 2, 2, 24)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_0 (QDense)             (None, 42)                4032      \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 42)                168       \n",
      "_________________________________________________________________\n",
      "dense_act_0 (QActivation)    (None, 42)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (QDense)             (None, 64)                2688      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_act_1 (QActivation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "output_dense (Dense)         (None, 10)                650       \n",
      "_________________________________________________________________\n",
      "output_softmax (Activation)  (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 14,225\n",
      "Trainable params: 13,892\n",
      "Non-trainable params: 333\n",
      "_________________________________________________________________\n",
      "conv_0 kernel: quantized_bits(6,0,1,alpha='auto_po2') bias: quantized_bits(6,0,1)\n",
      "conv_act_0 quantizer: quantized_relu(6,0)\n",
      "conv_1 kernel: quantized_bits(6,0,1,alpha='auto_po2') bias: quantized_bits(6,0,1)\n",
      "conv_act_1 quantizer: quantized_relu(6,0)\n",
      "conv_2 kernel: quantized_bits(6,0,1,alpha='auto_po2') bias: quantized_bits(6,0,1)\n",
      "conv_act_2 quantizer: quantized_relu(6,0)\n",
      "dense_0 kernel: quantized_bits(6,0,1,alpha='auto_po2') bias: None\n",
      "dense_act_0 quantizer: quantized_relu(6,0)\n",
      "dense_1 kernel: quantized_bits(6,0,1,alpha='auto_po2') bias: None\n",
      "dense_act_1 quantizer: quantized_relu(6,0)\n"
     ]
    }
   ],
   "source": [
    "from qkeras import QActivation\n",
    "from qkeras import QDense, QConv2DBatchnorm\n",
    "\n",
    "x = x_in = Input(input_shape)\n",
    "x = BatchNormalization()(x)\n",
    "for i,f in enumerate(filters_per_conv_layer):\n",
    "    print( ('Adding fused QConv+BN block {} with N={} filters').format(i,f) )\n",
    "    x = QConv2DBatchnorm(int(f), kernel_size=(3,3), strides=(1,1),\n",
    "                         kernel_quantizer=\"quantized_bits(6,0,1)\", \n",
    "                         bias_quantizer=\"quantized_bits(6,0,1)\",\n",
    "                         kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001), use_bias=False,\n",
    "                         name='conv_{}'.format(i))(x) \n",
    "    x = QActivation('quantized_relu(6)',name='conv_act_%i'%i)(x)\n",
    "    x = MaxPooling2D(pool_size = (2,2) )(x)\n",
    "x = Flatten()(x)\n",
    "for i,n in enumerate(neurons_per_dense_layer):\n",
    "  print( ('Adding QDense block {} with N={} neurons').format(i,n) )\n",
    "  x = QDense(n,\n",
    "            kernel_quantizer=\"quantized_bits(6,0,1)\",\n",
    "            kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001),name='dense_%i'%i, use_bias=False)(x)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = QActivation('quantized_relu(6)',name='dense_act_%i'%i)(x)\n",
    "x = Dense(int(n_classes),name='output_dense')(x)\n",
    "x_out = Activation('softmax',name='output_softmax')(x)\n",
    "qmodel = Model(inputs=[x_in], outputs=[x_out], name='qkeras')\n",
    "\n",
    "qmodel.summary()\n",
    "#Print the quantized layers\n",
    "for layer in qmodel.layers:\n",
    "    if hasattr(layer, \"kernel_quantizer\"):\n",
    "        print(layer.name, \"kernel:\", str(layer.kernel_quantizer_internal), \"bias:\", str(layer.bias_quantizer_internal))\n",
    "    elif hasattr(layer, \"quantizer\"):\n",
    "        print(layer.name, \"quantizer:\", str(layer.quantizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You see that a bias quantizer is defined, although we are not using a bias term for the layers. This is set automatically by QKeras. In addition, you'll note that ``alpha='auto_po2'``. This sets the weight scale per channel to be a power-of-2, such that an actual hardware implementation can be performed by just shifting the result of the convolutional/dense layer to the right or left by checking the sign of the scale and then taking the log2 of the scale.\n",
    "\n",
    "Let's now prune and train this model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel_pruned = tf.keras.models.clone_model( qmodel, clone_function=pruneFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 2.1839 - accuracy: 0.2743\n",
      "Epoch 00001: val_loss improved from inf to 2.28306, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00001: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 56s 872ms/step - loss: 2.1839 - accuracy: 0.2743 - val_loss: 2.2831 - val_accuracy: 0.2969\n",
      "Epoch 2/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 1.3395 - accuracy: 0.5993\n",
      "Epoch 00002: val_loss improved from 2.28306 to 1.88348, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00002: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 55s 857ms/step - loss: 1.3395 - accuracy: 0.5993 - val_loss: 1.8835 - val_accuracy: 0.3653\n",
      "Epoch 3/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.9230 - accuracy: 0.7455\n",
      "Epoch 00003: val_loss improved from 1.88348 to 1.35040, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00003: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 56s 868ms/step - loss: 0.9230 - accuracy: 0.7455 - val_loss: 1.3504 - val_accuracy: 0.5887\n",
      "Epoch 4/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.7385 - accuracy: 0.8049\n",
      "Epoch 00004: val_loss improved from 1.35040 to 0.99728, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00004: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 53s 834ms/step - loss: 0.7385 - accuracy: 0.8049 - val_loss: 0.9973 - val_accuracy: 0.7131\n",
      "Epoch 5/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.6482 - accuracy: 0.8320\n",
      "Epoch 00005: val_loss improved from 0.99728 to 0.74888, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00005: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 52s 819ms/step - loss: 0.6482 - accuracy: 0.8320 - val_loss: 0.7489 - val_accuracy: 0.7948\n",
      "Epoch 6/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5801 - accuracy: 0.8526\n",
      "Epoch 00006: val_loss improved from 0.74888 to 0.65987, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00006: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 54s 836ms/step - loss: 0.5801 - accuracy: 0.8526 - val_loss: 0.6599 - val_accuracy: 0.8264\n",
      "Epoch 7/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5430 - accuracy: 0.8605\n",
      "Epoch 00007: val_loss improved from 0.65987 to 0.61386, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00007: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 53s 825ms/step - loss: 0.5430 - accuracy: 0.8605 - val_loss: 0.6139 - val_accuracy: 0.8400\n",
      "Epoch 8/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.8687\n",
      "Epoch 00008: val_loss improved from 0.61386 to 0.60412, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00008: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 54s 838ms/step - loss: 0.5167 - accuracy: 0.8687 - val_loss: 0.6041 - val_accuracy: 0.8400\n",
      "Epoch 9/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4904 - accuracy: 0.8759\n",
      "Epoch 00009: val_loss improved from 0.60412 to 0.56660, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00009: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 55s 856ms/step - loss: 0.4904 - accuracy: 0.8759 - val_loss: 0.5666 - val_accuracy: 0.8504\n",
      "Epoch 10/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.8814\n",
      "Epoch 00010: val_loss improved from 0.56660 to 0.55619, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00010: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 54s 848ms/step - loss: 0.4707 - accuracy: 0.8814 - val_loss: 0.5562 - val_accuracy: 0.8559\n",
      "Epoch 11/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4565 - accuracy: 0.8836\n",
      "Epoch 00011: val_loss improved from 0.55619 to 0.54229, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00011: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 58s 907ms/step - loss: 0.4565 - accuracy: 0.8836 - val_loss: 0.5423 - val_accuracy: 0.8628\n",
      "Epoch 12/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4445 - accuracy: 0.8883\n",
      "Epoch 00012: val_loss did not improve from 0.54229\n",
      "\n",
      "Epoch 00012: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 56s 876ms/step - loss: 0.4445 - accuracy: 0.8883 - val_loss: 0.5431 - val_accuracy: 0.8608\n",
      "Epoch 13/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8910\n",
      "Epoch 00013: val_loss did not improve from 0.54229\n",
      "\n",
      "Epoch 00013: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 53s 828ms/step - loss: 0.4319 - accuracy: 0.8910 - val_loss: 0.5518 - val_accuracy: 0.8559\n",
      "Epoch 14/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4224 - accuracy: 0.8936\n",
      "Epoch 00014: val_loss improved from 0.54229 to 0.52242, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00014: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 54s 845ms/step - loss: 0.4224 - accuracy: 0.8936 - val_loss: 0.5224 - val_accuracy: 0.8655\n",
      "Epoch 15/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4150 - accuracy: 0.8949\n",
      "Epoch 00015: val_loss did not improve from 0.52242\n",
      "\n",
      "Epoch 00015: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 53s 836ms/step - loss: 0.4150 - accuracy: 0.8949 - val_loss: 0.5310 - val_accuracy: 0.8632\n",
      "Epoch 16/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4072 - accuracy: 0.8968\n",
      "Epoch 00016: val_loss improved from 0.52242 to 0.52104, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00016: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 55s 857ms/step - loss: 0.4072 - accuracy: 0.8968 - val_loss: 0.5210 - val_accuracy: 0.8630\n",
      "Epoch 17/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.4016 - accuracy: 0.8985\n",
      "Epoch 00017: val_loss did not improve from 0.52104\n",
      "\n",
      "Epoch 00017: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 55s 866ms/step - loss: 0.4016 - accuracy: 0.8985 - val_loss: 0.5349 - val_accuracy: 0.8597\n",
      "Epoch 18/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3968 - accuracy: 0.8994\n",
      "Epoch 00018: val_loss did not improve from 0.52104\n",
      "\n",
      "Epoch 00018: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 55s 854ms/step - loss: 0.3968 - accuracy: 0.8994 - val_loss: 0.5232 - val_accuracy: 0.8639\n",
      "Epoch 19/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3952 - accuracy: 0.8997\n",
      "Epoch 00019: val_loss improved from 0.52104 to 0.51174, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00019: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 56s 874ms/step - loss: 0.3952 - accuracy: 0.8997 - val_loss: 0.5117 - val_accuracy: 0.8658\n",
      "Epoch 20/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3900 - accuracy: 0.9016\n",
      "Epoch 00020: val_loss did not improve from 0.51174\n",
      "\n",
      "Epoch 00020: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 55s 854ms/step - loss: 0.3900 - accuracy: 0.9016 - val_loss: 0.5188 - val_accuracy: 0.8632\n",
      "Epoch 21/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3850 - accuracy: 0.9031\n",
      "Epoch 00021: val_loss did not improve from 0.51174\n",
      "\n",
      "Epoch 00021: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 56s 872ms/step - loss: 0.3850 - accuracy: 0.9031 - val_loss: 0.5141 - val_accuracy: 0.8636\n",
      "Epoch 22/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3835 - accuracy: 0.9033\n",
      "Epoch 00022: val_loss improved from 0.51174 to 0.49494, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00022: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 55s 863ms/step - loss: 0.3835 - accuracy: 0.9033 - val_loss: 0.4949 - val_accuracy: 0.8713\n",
      "Epoch 23/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - ETA: 0s - loss: 0.3786 - accuracy: 0.9043\n",
      "Epoch 00023: val_loss did not improve from 0.49494\n",
      "\n",
      "Epoch 00023: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 57s 895ms/step - loss: 0.3786 - accuracy: 0.9043 - val_loss: 0.5069 - val_accuracy: 0.8710\n",
      "Epoch 24/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3780 - accuracy: 0.9049\n",
      "Epoch 00024: val_loss did not improve from 0.49494\n",
      "\n",
      "Epoch 00024: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 51s 800ms/step - loss: 0.3780 - accuracy: 0.9049 - val_loss: 0.5185 - val_accuracy: 0.8675\n",
      "Epoch 25/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3766 - accuracy: 0.9053\n",
      "Epoch 00025: val_loss did not improve from 0.49494\n",
      "\n",
      "Epoch 00025: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 52s 813ms/step - loss: 0.3766 - accuracy: 0.9053 - val_loss: 0.5222 - val_accuracy: 0.8660\n",
      "Epoch 26/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3742 - accuracy: 0.9057\n",
      "Epoch 00026: val_loss did not improve from 0.49494\n",
      "\n",
      "Epoch 00026: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 55s 852ms/step - loss: 0.3742 - accuracy: 0.9057 - val_loss: 0.5309 - val_accuracy: 0.8617\n",
      "Epoch 27/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3729 - accuracy: 0.9066\n",
      "Epoch 00027: val_loss did not improve from 0.49494\n",
      "\n",
      "Epoch 00027: saving model to quantized_cnn_weights_best.h5\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.00030000000260770325.\n",
      "64/64 [==============================] - 56s 869ms/step - loss: 0.3729 - accuracy: 0.9066 - val_loss: 0.5126 - val_accuracy: 0.8673\n",
      "Epoch 28/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3495 - accuracy: 0.9139\n",
      "Epoch 00028: val_loss improved from 0.49494 to 0.47341, saving model to quantized_cnn_model_best.h5\n",
      "\n",
      "Epoch 00028: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 54s 838ms/step - loss: 0.3495 - accuracy: 0.9139 - val_loss: 0.4734 - val_accuracy: 0.8827\n",
      "Epoch 29/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.9164\n",
      "Epoch 00029: val_loss did not improve from 0.47341\n",
      "\n",
      "Epoch 00029: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 58s 900ms/step - loss: 0.3408 - accuracy: 0.9164 - val_loss: 0.4802 - val_accuracy: 0.8819\n",
      "Epoch 30/30\n",
      "64/64 [==============================] - ETA: 0s - loss: 0.3393 - accuracy: 0.9178\n",
      "Epoch 00030: val_loss did not improve from 0.47341\n",
      "\n",
      "Epoch 00030: saving model to quantized_cnn_weights_best.h5\n",
      "64/64 [==============================] - 53s 827ms/step - loss: 0.3393 - accuracy: 0.9178 - val_loss: 0.4755 - val_accuracy: 0.8804\n",
      "\n",
      " It took 27.77394591967265 minutes to train!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LOSS        = tf.keras.losses.CategoricalCrossentropy()\n",
    "OPTIMIZER   = tf.keras.optimizers.Adam(learning_rate=3E-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True) \n",
    "qmodel_pruned.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "            tf.keras.callbacks.ModelCheckpoint('quantized_cnn_model_best.h5',monitor=\"val_loss\",verbose=1,save_best_only=True), \n",
    "            tf.keras.callbacks.ModelCheckpoint('quantized_cnn_weights_best.h5',monitor=\"val_loss\",verbose=1,save_weights_only=True),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001, cooldown=2, min_lr=1E-6),\n",
    "            pruning_callbacks.UpdatePruningStep()\n",
    "            ]      \n",
    "\n",
    "start = time.time()\n",
    "history = qmodel_pruned.fit(train,\n",
    "                      epochs =  epochs,\n",
    "                      validation_data = val,\n",
    "                      callbacks = callbacks,\n",
    "                      steps_per_epoch = steps_per_epoch,  \n",
    "                      verbose=1)     \n",
    "end = time.time()\n",
    "print('\\n It took {} minutes to train!\\n'.format( (end - start)/60.))\n",
    "\n",
    "qmodel_pruned.load_weights('quantized_cnn_weights_best.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that training a model quantization aware, takes almost twice as long as when not quantizing during training!\n",
    "The validation accuracy is very similar to that of the floating point model equivalent. \n",
    "\n",
    "### Performance\n",
    "Let's look at some ROC curves to compare the performance. Lets choose a few numbers so it doesn't get confusing. Feel free to change the numbers in ``labels``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "814/814 [==============================] - 3s 3ms/step - loss: 0.4649 - accuracy: 0.8843\n",
      "814/814 [==============================] - 7s 8ms/step - loss: 0.4854 - accuracy: 0.8744\n",
      "Keras accuracy = 0.8842578530311584 , QKeras 6-bit accuracy = 0.8743853569030762\n"
     ]
    }
   ],
   "source": [
    "predict_baseline    = model_pruned.predict(X_test)\n",
    "test_score_baseline = model_pruned.evaluate(X_test, Y_test)\n",
    "\n",
    "predict_qkeras    = qmodel_pruned.predict(X_test)\n",
    "test_score_qkeras = qmodel_pruned.evaluate(X_test, Y_test)\n",
    "\n",
    "print('Keras accuracy = {} , QKeras 6-bit accuracy = {}'.format(test_score_baseline[1],test_score_qkeras[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting ROC for labels ['0', '1', '9']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.2, 0.83, 'Accuracy Keras = 88.4% QKeras 6-bit = 87.4%')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# labels=['%i'%nr for nr in range (0,n_classes)] #If you want to look at all the labels\n",
    "labels = ['0','1','9'] #Lets look at only a few labels, here for digits 0, 1 and 9\n",
    "print('Plotting ROC for labels {}'.format(labels))\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df_q = pd.DataFrame()\n",
    "fpr  = {}\n",
    "tpr  = {}\n",
    "auc1 = {}\n",
    "fpr_q  = {}\n",
    "tpr_q  = {}\n",
    "auc1_q = {}\n",
    "%matplotlib inline\n",
    "colors  = ['#67001f','#b2182b','#d6604d','#f4a582','#fddbc7','#d1e5f0','#92c5de','#4393c3','#2166ac','#053061']\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "for i, label in enumerate(labels):\n",
    "    df[label] = Y_test[:,int(label)]\n",
    "    df[label + '_pred'] = predict_baseline[:,int(label)]\n",
    "    fpr[label], tpr[label], threshold = metrics.roc_curve(df[label],df[label+'_pred'])\n",
    "    auc1[label] = metrics.auc(fpr[label], tpr[label])\n",
    "    \n",
    "    df_q[label] = Y_test[:,int(label)]\n",
    "    df_q[label + '_pred'] = predict_qkeras[:,int(label)]\n",
    "    fpr_q[label], tpr_q[label], threshold_q = metrics.roc_curve(df_q[label],df_q[label+'_pred'])\n",
    "    auc1_q[label] = metrics.auc(fpr_q[label], tpr_q[label])\n",
    "    \n",
    "    plt.plot(fpr[label],tpr[label]    ,label=r'{}, AUC Keras = {:.3f} AUC QKeras = {:.3f})'.format(label,auc1[label],auc1_q[label]), linewidth=1.5,c=colors[i],linestyle='solid')\n",
    "    plt.plot(fpr_q[label],tpr_q[label], linewidth=1.5,c=colors[i],linestyle='dotted')\n",
    "\n",
    "plt.semilogx()\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.xlim(0.0005,1.)\n",
    "plt.ylim(0.2,1.2)\n",
    "plt.legend(loc='lower right')\n",
    "plt.figtext(0.2, 0.83,r'Accuracy Keras = {:.1f}% QKeras 6-bit = {:.1f}%'.format(test_score_baseline[1]*100,test_score_qkeras[1]*100), wrap=True, horizontalalignment='left',verticalalignment='center')\n",
    "      \n",
    "\n",
    "#     getSingleRoc(X_test, labels, Y_test, model_tmp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in AUC between the fp32 Keras model and the 6-bit QKeras model, is small, as we have seen for the previous examples. As a bonus exercise, you can find an exercise below where we use AutoQKeras to find the best heterogeneously quantized model, given a set of resource and accuracy constriants.\n",
    "\n",
    "Now, let's compare the two models after logic synthesis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment with hls4ml\n",
    "\n",
    "In this part, we will take the two models we trained above (the floating-point 32 Keras model and the 6-bit QKeras model), and synthesize them with hls4ml. Although your models are probably in memory, let's load them from scratch. We need to pass the appropriate custom QKeras/pruning layers when loading, and remove the pruning parameters that were saved together with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper\n",
    "\n",
    "model = tf.keras.models.load_model('pruned_cnn_model_best.h5',custom_objects={'PruneLowMagnitude': pruning_wrapper.PruneLowMagnitude,'QDense': QDense, 'QConv2DBatchnorm': QConv2DBatchnorm, 'QActivation': QActivation})\n",
    "model  = strip_pruning(model)\n",
    "\n",
    "qmodel = tf.keras.models.load_model('quantized_cnn_model_best.h5',custom_objects={'PruneLowMagnitude': pruning_wrapper.PruneLowMagnitude,'QDense': QDense, 'QConv2DBatchnorm': QConv2DBatchnorm, 'QActivation': QActivation})\n",
    "qmodel  = strip_pruning(qmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to define the hls4ml and Vivado configurations. Two things will change with respect to what was done in the previous exercises. First, we will use ``IOType= 'io_stream'`` in the Vivado configuration.\n",
    "\n",
    "**You must use ``IOType= 'io_stream'`` if attempting to synthesize a convolutional neural network.**\n",
    "\n",
    "The CNN implementation in hls4ml is based on streams, which are synthesized in hardware as first in, first out (FIFO) buffers. A sliding window buffer is used to hold all elements of a kernel window that are needed to compute one output element. We pre-compute the positions in the sliding window where a given input element isused, and store this information as a binary mask.\n",
    "\n",
    "This is illustrated  in the gif below. The example shows a 3x3 convolution over a 6x6 image. The left image shows the mask of each pixel (we represent this as a number) and the right image shows the contents of the internal sliding window (an array of FIFOs, corresponding to the 3x3 kernel).\n",
    "\n",
    "![alt text](images/conv2d_animation.gif \"The implementation of convolutional layers in hls4ml is based on streams\")\n",
    "\n",
    "Lastly, we will use ``['Strategy'] = 'Latency'`` for all the layers in the hls4ml configuration. If one layer would have >4096 elements, we sould set ``['Strategy'] = 'Resource'`` for that layer, or increase the reuse factor by hand. You can find examples of how to do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_2, layer type: Input\n",
      "Layer name: batch_normalization_6, layer type: BatchNormalization\n",
      "Layer name: conv_0, layer type: Conv2D\n",
      "  -> Activation (linear), layer name: conv_0\n",
      "Layer name: batch_normalization_7, layer type: BatchNormalization\n",
      "Layer name: conv_act_0, layer type: Activation\n",
      "Layer name: max_pooling2d_3, layer type: MaxPooling2D\n",
      "Layer name: conv_1, layer type: Conv2D\n",
      "  -> Activation (linear), layer name: conv_1\n",
      "Layer name: batch_normalization_8, layer type: BatchNormalization\n",
      "Layer name: conv_act_1, layer type: Activation\n",
      "Layer name: max_pooling2d_4, layer type: MaxPooling2D\n",
      "Layer name: conv_2, layer type: Conv2D\n",
      "  -> Activation (linear), layer name: conv_2\n",
      "Layer name: batch_normalization_9, layer type: BatchNormalization\n",
      "Layer name: conv_act_2, layer type: Activation\n",
      "Layer name: max_pooling2d_5, layer type: MaxPooling2D\n",
      "Layer name: dense_0, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_0\n",
      "Layer name: batch_normalization_10, layer type: BatchNormalization\n",
      "Layer name: dense_act_0, layer type: Activation\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: batch_normalization_11, layer type: BatchNormalization\n",
      "Layer name: dense_act_1, layer type: Activation\n",
      "Layer name: output_dense, layer type: Dense\n",
      "  -> Activation (linear), layer name: output_dense\n",
      "Layer name: output_softmax, layer type: Activation\n",
      "Model\n",
      "  Precision:         ap_fixed<16,6>\n",
      "  ReuseFactor:       1\n",
      "  Strategy:          Latency\n",
      "LayerName\n",
      "  input_2\n",
      "    Precision\n",
      "      result:        ap_fixed<16,6>\n",
      "    Strategy:        Latency\n",
      "    ReuseFactor:     1\n",
      "  batch_normalization_6\n",
      "    Precision\n",
      "      scale:         ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  conv_0\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  conv_0_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  batch_normalization_7\n",
      "    Precision\n",
      "      scale:         ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  conv_act_0\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  max_pooling2d_3\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    Strategy:        Latency\n",
      "    ReuseFactor:     1\n",
      "  conv_1\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  conv_1_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  batch_normalization_8\n",
      "    Precision\n",
      "      scale:         ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  conv_act_1\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  max_pooling2d_4\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    Strategy:        Latency\n",
      "    ReuseFactor:     1\n",
      "  conv_2\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  conv_2_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  batch_normalization_9\n",
      "    Precision\n",
      "      scale:         ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  conv_act_2\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  max_pooling2d_5\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    Strategy:        Latency\n",
      "    ReuseFactor:     1\n",
      "  dense_0\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  dense_0_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  batch_normalization_10\n",
      "    Precision\n",
      "      scale:         ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  dense_act_0\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  dense_1\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  dense_1_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  batch_normalization_11\n",
      "    Precision\n",
      "      scale:         ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  dense_act_1\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  output_dense\n",
      "    Precision\n",
      "      weight:        ap_fixed<16,6>\n",
      "      bias:          ap_fixed<16,6>\n",
      "      result:        ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    Strategy:        Latency\n",
      "  output_dense_linear\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    table_t:         ap_fixed<18,8>\n",
      "    Strategy:        Latency\n",
      "  output_softmax\n",
      "    Precision:       ap_fixed<16,6>\n",
      "    ReuseFactor:     1\n",
      "    table_size:      1024\n",
      "    exp_table_t:     ap_fixed<18,8,AP_RND,AP_SAT>\n",
      "    inv_table_t:     ap_fixed<18,8,AP_RND,AP_SAT>\n",
      "    Strategy:        Stable\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_2, layer type: InputLayer, current shape: [[None, 32, 32, 3]]\n",
      "Layer name: batch_normalization_6, layer type: BatchNormalization, current shape: [[None, 32, 32, 3]]\n",
      "Layer name: conv_0, layer type: Conv2D, current shape: [[None, 32, 32, 3]]\n",
      "Layer name: batch_normalization_7, layer type: BatchNormalization, current shape: [[None, 30, 30, 16]]\n",
      "Layer name: conv_act_0, layer type: Activation, current shape: [[None, 30, 30, 16]]\n",
      "Layer name: max_pooling2d_3, layer type: MaxPooling2D, current shape: [[None, 30, 30, 16]]\n",
      "Layer name: conv_1, layer type: Conv2D, current shape: [[None, 15, 15, 16]]\n",
      "Layer name: batch_normalization_8, layer type: BatchNormalization, current shape: [[None, 13, 13, 16]]\n",
      "Layer name: conv_act_1, layer type: Activation, current shape: [[None, 13, 13, 16]]\n",
      "Layer name: max_pooling2d_4, layer type: MaxPooling2D, current shape: [[None, 13, 13, 16]]\n",
      "Layer name: conv_2, layer type: Conv2D, current shape: [[None, 6, 6, 16]]\n",
      "Layer name: batch_normalization_9, layer type: BatchNormalization, current shape: [[None, 4, 4, 24]]\n",
      "Layer name: conv_act_2, layer type: Activation, current shape: [[None, 4, 4, 24]]\n",
      "Layer name: max_pooling2d_5, layer type: MaxPooling2D, current shape: [[None, 4, 4, 24]]\n",
      "Layer name: dense_0, layer type: Dense, current shape: [[None, 96]]\n",
      "Layer name: batch_normalization_10, layer type: BatchNormalization, current shape: [[None, 42]]\n",
      "Layer name: dense_act_0, layer type: Activation, current shape: [[None, 42]]\n",
      "Layer name: dense_1, layer type: Dense, current shape: [[None, 42]]\n",
      "Layer name: batch_normalization_11, layer type: BatchNormalization, current shape: [[None, 64]]\n",
      "Layer name: dense_act_1, layer type: Activation, current shape: [[None, 64]]\n",
      "Layer name: output_dense, layer type: Dense, current shape: [[None, 64]]\n",
      "Layer name: output_softmax, layer type: Softmax, current shape: [[None, 10]]\n",
      "Creating HLS model\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import hls4ml\n",
    "import plotting\n",
    "\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "\n",
    "#First, the baseline model\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "# Set the precision and reuse factor for the full model\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config['Model']['ReuseFactor'] = 1\n",
    "\n",
    "# Create an entry for each layer, here you can for instance change the strategy for a layer to 'resource' \n",
    "# or increase the reuse factor individually for large layers.\n",
    "# In this case, we designed the model to be small enough for a fully parallel implementation \n",
    "# so we use the latency strategy and reuse factor of 1 for all layers.\n",
    "for Layer in hls_config['LayerName'].keys():\n",
    "    hls_config['LayerName'][Layer]['Strategy'] = 'Latency'\n",
    "    hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "#If you want best numerical performance for high-accuray models, while the default latency strategy is faster but numerically more unstable\n",
    "hls_config['LayerName']['output_softmax']['Strategy'] = 'Stable'\n",
    "plotting.print_dict(hls_config)\n",
    "  \n",
    "cfg = hls4ml.converters.create_vivado_config()\n",
    "cfg['IOType']     = 'io_stream' # Must set this if using CNNs!\n",
    "cfg['HLSConfig']  = hls_config\n",
    "cfg['KerasModel'] = model\n",
    "cfg['OutputDir']  = 'baseline_cnn/'\n",
    "cfg['XilinxPart'] = 'xcu250-figd2104-2L-e'\n",
    "  \n",
    "hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "hls_model.compile()\n",
    "#hls_model.build(csim=False, synth=True, vsynth=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_4, layer type: Input\n",
      "Layer name: batch_normalization_18, layer type: BatchNormalization\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "ERROR: Unsupported layer type: QConv2DBatchnorm",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-cd2dfdba5b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Then our QKeras model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mhls_config_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhls4ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig_from_keras_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgranularity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mhls_config_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ReuseFactor'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mhls_config_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LayerName'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'output_softmax'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Strategy'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Stable'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/hls4ml-tutorial-0.5.0/lib/python3.7/site-packages/hls4ml/utils/config.py\u001b[0m in \u001b[0;36mconfig_from_keras_model\u001b[0;34m(model, granularity, default_precision, default_reuse_factor)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkeras_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeras_layer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeras_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msupported_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ERROR: Unsupported layer type: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeras_layer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mskip_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: ERROR: Unsupported layer type: QConv2DBatchnorm"
     ]
    }
   ],
   "source": [
    "# Then our QKeras model\n",
    "hls_config_q = hls4ml.utils.config_from_keras_model(qmodel, granularity='name')\n",
    "hls_config_q['Model']['ReuseFactor'] = 1\n",
    "hls_config_q['LayerName']['output_softmax']['Strategy'] = 'Stable'\n",
    "plotting.print_dict(hls_config_q)\n",
    "  \n",
    "cfg_q = hls4ml.converters.create_vivado_config()\n",
    "cfg_q['IOType']     = 'io_stream' # Must set this if using CNNs!\n",
    "cfg_q['HLSConfig']  = hls_config\n",
    "cfg_q['KerasModel'] = model\n",
    "cfg_q['OutputDir']  = 'baseline_cnn/'\n",
    "cfg_q['XilinxPart'] = 'xcu250-figd2104-2L-e'\n",
    "  \n",
    "hls_model_q = hls4ml.converters.keras_to_hls(cfg_q)\n",
    "hls_model_q.compile()\n",
    "#hls_model.build(csim=False, synth=True, vsynth=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

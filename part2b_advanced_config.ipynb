{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before You Start\n",
    "\n",
    "The current set of notebooks are under constant development.\n",
    "\n",
    "## Update Tutorial Repository\n",
    "\n",
    "If you have previously cloned the tutorial repository, you may need to get the latest versions of the notebooks.\n",
    "\n",
    "First check the status of your repository:\n",
    "```\n",
    "cd hls4ml-tutorial\n",
    "make clean\n",
    "git status \n",
    "```\n",
    "\n",
    "You may have some _modified_ notebooks. For example:\n",
    "\n",
    "```\n",
    "# On branch csee-e6868-spring2022\n",
    "# Changes not staged for commit:\n",
    "#   (use \"git add <file>...\" to update what will be committed)\n",
    "#   (use \"git checkout -- <file>...\" to discard changes in working directory)\n",
    "#\n",
    "#\tmodified:   part1_getting_started.ipynb\n",
    "#\tmodified:   part2_advanced_config.ipynb\n",
    "#\n",
    "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n",
    "```\n",
    "\n",
    "You can make a copy of those modified notebooks if you had significat changes, otherwise the easiest thing to do is to discard those changes.\n",
    "\n",
    "**ATTENTION** You will loose your local changes!\n",
    "\n",
    "```\n",
    "git checkout *.ipynb\n",
    "```\n",
    "\n",
    "At this point, you can update you copy of the repository:\n",
    "```\n",
    "git pull\n",
    "```\n",
    "\n",
    "\n",
    "## Update Conda Environment\n",
    "\n",
    "It is likely that you are running this notebook in the Conda environment `hls4ml-tutorial-cu`.\n",
    "\n",
    "If you did not do that yet, you should update the `hls4ml` packages with the latest changes in the working branch.\n",
    "\n",
    "```\n",
    "conda activate hls4ml-tutorial-cu\n",
    "pip uninstall hls4ml\n",
    "pip install git+https://github.com/GiuseppeDiGuglielmo/hls4ml.git@gdg/cosmetics#egg=hls4ml[profiling]\n",
    "```\n",
    "\n",
    "You may need to restart the Jupyter notebook.\n",
    "\n",
    "\n",
    "# Part 2b: Advanced Design Space Exploration\n",
    "\n",
    "In this notebook, we will leverage Python programming to scan the design space of our HLS model. \n",
    "\n",
    "**This is just a pedagocical exercise. Many frameworks are available to scan the design space and find optimal architectures, for example [AutoKeras](https://autokeras.com)**.\n",
    "\n",
    "\n",
    "## Setup\n",
    "\n",
    "As we did in the previous notebooks, let's import the libraries, call the magic functions, and setup the environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import hls4ml\n",
    "%matplotlib inline\n",
    "import os\n",
    "os.environ['PATH'] = '/opt/xilinx/Vivado/2019.2/bin:' + os.environ['PATH']\n",
    "def is_tool(name):\n",
    "    from distutils.spawn import find_executable\n",
    "    return find_executable(name) is not None\n",
    "\n",
    "print('-----------------------------------')\n",
    "if not is_tool('vivado_hls'):\n",
    "    print('Xilinx Vivado HLS is NOT in the PATH')\n",
    "else:\n",
    "    print('Xilinx Vivado HLS is in the PATH')\n",
    "print('-----------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset and the model\n",
    "\n",
    "In [Part 1](part1_getting_started.ipynb), we saved the preprocessed dataset and model to files. Let's load them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "X_train_val = np.load('X_train_val.npy')\n",
    "X_test = np.load('X_test.npy')\n",
    "y_train_val = np.load('y_train_val.npy')\n",
    "y_test = np.load('y_test.npy', allow_pickle=True)\n",
    "classes = np.load('classes.npy', allow_pickle=True)\n",
    "\n",
    "# Load Keras model\n",
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('model_1/KERAS_check_best_model.h5')\n",
    "y_keras = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DSE\n",
    "\n",
    "Let's combine everything together Python programming and `Precision` and `Reuse Factor` knobs.\n",
    "\n",
    "First we encapsulate in a function the creation of a hls4ml configuration dictionary and hls4ml model creation, compilation and built (C-synthesis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def process_hls4ml(model, fxd_w, fxd_i, rf, fpga_part, dse_hls_results):\n",
    "    # Generate a hls4ml configuration dictionary from the Keras model\n",
    "    config = hls4ml.utils.config_from_keras_model(model, granularity='Model')\n",
    "    \n",
    "    # Update the knobs\n",
    "    config['Model']['ReuseFactor'] = rf\n",
    "    config['Model']['Precision'] = 'ap_fixed<' + str(fxd_w) + ',' + str(fxd_i) + '>'\n",
    "\n",
    "    # Each hls4ml project / synthesis run must have its own working directory \n",
    "    output_dir = 'model_1/hls4ml_prj_rf' + str(rf) + '_fxd' + str(fxd_w) + '.' + str(fxd_i)\n",
    "\n",
    "    # Create an HLS model from the Keras model and the updated hls4ml configuration dictionary\n",
    "    hls_model = hls4ml.converters.convert_from_keras_model(model,\n",
    "                                                           hls_config=config,\n",
    "                                                           output_dir=output_dir,\n",
    "                                                           part=fpga_part)\n",
    "    _ = hls_model.compile()\n",
    "\n",
    "    # C-synthesis\n",
    "    start_time = time.time()\n",
    "    hls_results = hls_model.build(csim=False)\n",
    "    exec_time = time.time() - start_time\n",
    "\n",
    "    # Add extra information to the synthesis results\n",
    "    hls_results[\"ExecutionTime\"] = exec_time\n",
    "    hls_results[\"WbitsFixedPoint\"] = fxd_w\n",
    "    hls_results[\"IbitsFixedPoint\"] = fxd_i\n",
    "    hls_results[\"FPGApart\"] = fpga_part\n",
    "    \n",
    "    # Return results to the shared dictionary\n",
    "    dse_hls_results[rf] = hls_results\n",
    "    return hls_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the Python `multiprocessing` package to run multiple synthesis runs in parallel.\n",
    "\n",
    "**ATTENTION: Pay attention to the amount of memory and CPU cores/threads available on your host!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "def get_size(bytes, suffix=\"B\"):\n",
    "    \"\"\"\n",
    "    Scale bytes to its proper format\n",
    "    e.g:\n",
    "        1253656 => '1.20MB'\n",
    "        1253656678 => '1.17GB'\n",
    "    \"\"\"\n",
    "    factor = 1024\n",
    "    for unit in [\"\", \"K\", \"M\", \"G\", \"T\", \"P\"]:\n",
    "        if bytes < factor:\n",
    "            return f\"{bytes:.2f}{unit}{suffix}\"\n",
    "        bytes /= factor\n",
    "\n",
    "# Memory Information\n",
    "print(\"=\"*33, \"Memory Information\", \"=\"*33)\n",
    "\n",
    "# Get the memory details\n",
    "svmem = psutil.virtual_memory()\n",
    "print(f\"Total: {get_size(svmem.total)}\")\n",
    "print(f\"Available: {get_size(svmem.available)}\")\n",
    "print(f\"Used: {get_size(svmem.used)}\")\n",
    "print(f\"Percentage: {svmem.percent}%\")\n",
    "print(\"=\"*18, \"SWAP\", \"=\"*18)\n",
    "# Get the swap memory details (if exists)\n",
    "swap = psutil.swap_memory()\n",
    "print(f\"Total: {get_size(swap.total)}\")\n",
    "print(f\"Free: {get_size(swap.free)}\")\n",
    "print(f\"Used: {get_size(swap.used)}\")\n",
    "print(f\"Percentage: {swap.percent}%\")\n",
    "\n",
    "# CPU Information\n",
    "print(\"=\"*38, \"CPU Info\", \"=\"*38)\n",
    "\n",
    "# Number of cores\n",
    "print(\"Physical cores:\", psutil.cpu_count(logical=False))\n",
    "print(\"Total cores:\", psutil.cpu_count(logical=True))\n",
    "# CPU frequencies\n",
    "cpufreq = psutil.cpu_freq()\n",
    "print(f\"Max Frequency: {cpufreq.max:.2f}Mhz\")\n",
    "print(f\"Min Frequency: {cpufreq.min:.2f}Mhz\")\n",
    "print(f\"Current Frequency: {cpufreq.current:.2f}Mhz\")\n",
    "# CPU usage\n",
    "print(\"CPU Usage Per Core:\")\n",
    "for i, percentage in enumerate(psutil.cpu_percent(percpu=True, interval=1)):\n",
    "    print(f\"Core {i}: {percentage}%\")\n",
    "print(f\"Total CPU Usage: {psutil.cpu_percent()}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also monitor the situation at runtime with the `htop` command in a console.\n",
    "\n",
    "Let's start with this initial configuration, but later you can change it as you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import multiprocessing\n",
    "\n",
    "# Choose the target FPGA chip\n",
    "#target_fpga_part='xczu7ev-ffvc1156-2-e' # ZCU106\n",
    "target_fpga_part='xczu3eg-sbva484-1-e' # Ultra96\n",
    "#target_fpga_part='xc7z020clg400-1' # Pynq-Z1\n",
    "#target_fpga_part='xc7z007sclg225-1' # Minized\n",
    "\n",
    "# DSE: Cartesian product of ReuseFactor and Precision\n",
    "reuse_factor_values = [1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1028]\n",
    "fxd_w_values = [16]\n",
    "#, 14, 12, 10, 8]\n",
    "fxd_i_values = [6]\n",
    "#, 4]\n",
    "\n",
    "# Append here the processes\n",
    "processes = list()\n",
    "\n",
    "# DSE results shared among processes\n",
    "manager = multiprocessing.Manager()\n",
    "dse_hls_results = manager.dict()\n",
    "\n",
    "# Swipe over the Precision and ReuseFactor values and spawn synthesis processes\n",
    "for fxd_w in fxd_w_values:\n",
    "    for fxd_i in fxd_i_values:\n",
    "        for rf in reuse_factor_values:\n",
    "            t = multiprocessing.Process(target=process_hls4ml, args=(model, fxd_w, fxd_i, rf, target_fpga_part, dse_hls_results))\n",
    "            processes.append(t)\n",
    "            t.start()\n",
    "\n",
    "# Wait for completion\n",
    "for t in processes:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print DSE results on console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_hls_results(hls_results):\n",
    "    print('-----------------------------------')\n",
    "    #print(hls_results) # Print hashmap\n",
    "    print(\"FPGA part: {}\".format(hls_results['FPGApart']))\n",
    "    print(\"Fixed-Point Word Size: {}\".format(hls_results['WbitsFixedPoint']))\n",
    "    print(\"Fixed-Point Integer-Part Size: {}\".format(hls_results['IbitsFixedPoint']))\n",
    "    print(\"Execution Time: {} s\".format(hls_results['ExecutionTime']))\n",
    "    print(\"Estimated Clock Period: {} ns\".format(hls_results['EstimatedClockPeriod']))\n",
    "    print(\"Best/Worst Latency:     {} / {}\".format(hls_results['BestLatency'], hls_results['WorstLatency']))\n",
    "    print(\"Interval Min/Max:       {} / {}\".format(hls_results['IntervalMin'], hls_results['IntervalMax']))\n",
    "    print(\"BRAM_18K:               {} (Aval. {})\".format(hls_results['BRAM_18K'], hls_results['AvailableBRAM_18K']))\n",
    "    print(\"DSP48E:                 {} (Aval. {})\".format(hls_results['DSP48E'], hls_results['AvailableDSP48E']))\n",
    "    print(\"FF:                     {} (Aval. {})\".format(hls_results['FF'], hls_results['AvailableFF']))\n",
    "    print(\"LUT:                    {} (Aval. {})\".format(hls_results['LUT'], hls_results['AvailableLUT']))\n",
    "    print(\"URAM:                   {} (Aval. {})\".format(hls_results['URAM'], hls_results['AvailableURAM']))\n",
    "    print('-----------------------------------')\n",
    "\n",
    "for rf in dse_hls_results.keys():\n",
    "    print_hls_results(dse_hls_results[rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a plot 2D function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import matplotlib.ticker as plticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# available_resources: we are plotting some hw resources as DSPs; false if resource is like runtime, latency etc\n",
    "# show_values: show values as labels on the data points\n",
    "# show_precision: show fixed-point precision as a labels on the data points\n",
    "# xscale_log: log2 scale on x axis\n",
    "# yscale_log: log2 scale on y axis\n",
    "def plot_hls_results(dse_hls_results, resource_label, unit='HLS Estimates', available_resources=True, show_values=False, show_precision=True, xscale_log=False, yscale_log=False):\n",
    "\n",
    "    # Reorder the results according to the ReuseFactor (dictionary key)\n",
    "    dse_hls_results_ordered = collections.OrderedDict(sorted(dse_hls_results.items(), key=lambda x:x[0], reverse=False))\n",
    "\n",
    "    # Fonts\n",
    "    SMALL_SIZE = 8\n",
    "    MEDIUM_SIZE = 10\n",
    "    BIGGER_SIZE = 14\n",
    "    plt.rc('font', size=MEDIUM_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=BIGGER_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=BIGGER_SIZE)     # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=BIGGER_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=BIGGER_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE)   # fontsize of the figure title\n",
    "    \n",
    "    # Extract values of the x and y axes \n",
    "    reuse_factor_x_axis = np.array(list(dse_hls_results_ordered.keys()))\n",
    "    resource_usage_y_axis = []\n",
    "    fxd_w_precision = []\n",
    "    fxd_i_precision = []\n",
    "    resource_available_y_axis=[]\n",
    "    fpga_parts=[]\n",
    "    \n",
    "    for i, d in dse_hls_results_ordered.items():\n",
    "        resource_usage_y_axis.append(int(dse_hls_results_ordered[i][resource_label]))\n",
    "    if (available_resources):\n",
    "        for i, d in dse_hls_results_ordered.items():\n",
    "            resource_available_y_axis.append(int(dse_hls_results_ordered[i]['Available' + resource_label]))\n",
    "    for i, d in dse_hls_results_ordered.items():\n",
    "        fxd_w_precision.append(int(dse_hls_results_ordered[i]['WbitsFixedPoint']))\n",
    "    for i, d in dse_hls_results_ordered.items():\n",
    "        fxd_i_precision.append(int(dse_hls_results_ordered[i]['IbitsFixedPoint']))\n",
    "    for i, d in dse_hls_results_ordered.items():\n",
    "        fpga_parts.append(dse_hls_results_ordered[i]['FPGApart'])\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xlabel('Reuse Factor')\n",
    "    \n",
    "    ax.set_ylabel(resource_label + ' (' + unit + ')')\n",
    "    ax.plot(reuse_factor_x_axis, resource_usage_y_axis, linestyle='--', marker='o')\n",
    "\n",
    "    if (available_resources):\n",
    "        ax.axhline(y=resource_available_y_axis[0], color='r', linestyle='-', label = resource_label + ' (Available)')\n",
    "        ax.legend(loc='upper right')\n",
    "\n",
    "    ax.set_xticks(reuse_factor_x_axis)    \n",
    "    ax.grid(True)\n",
    "    plt.figtext(0.90, 0.90, 'hls4ml', fontweight='bold', wrap=True, horizontalalignment='right', fontsize=14)\n",
    "    plt.figtext(0.4, 0.90, fpga_parts[0], wrap=True, horizontalalignment='right', fontsize=14)\n",
    "    \n",
    "    if xscale_log: ax.set_xscale('log', base=2)\n",
    "    if yscale_log: ax.set_yscale('log', base=2)\n",
    "    \n",
    "    if show_values:\n",
    "        for x,y in zip(reuse_factor_x_axis,resource_usage_y_axis):\n",
    "            label = \"{:d}\".format(y)\n",
    "            plt.annotate(label, # this is the text\n",
    "                     (x,y), # this is the point to label\n",
    "                     textcoords=\"offset points\", # how to position the text\n",
    "                     xytext=(0,10), # distance from text to points (x,y)\n",
    "                     ha='center') # horizontal alignment can be left, right or center\n",
    "    if show_precision:\n",
    "        for x,y,w,i in zip(reuse_factor_x_axis,resource_usage_y_axis,fxd_w_precision,fxd_i_precision):\n",
    "            label = '<{},{}>'.format(w,i)\n",
    "            plt.annotate(label, # this is the text\n",
    "                     (x,y), # this is the point to label\n",
    "                     textcoords=\"offset points\", # how to position the text\n",
    "                     xytext=(0,10), # distance from text to points (x,y)\n",
    "                     ha='center') # horizontal alignment can be left, right or center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some of the resources from the previous DSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hls_results(dse_hls_results, 'ExecutionTime', unit='s', available_resources=False, xscale_log=True)\n",
    "plot_hls_results(dse_hls_results, 'DSP48E', xscale_log=True)\n",
    "plot_hls_results(dse_hls_results, 'BRAM_18K', xscale_log=True)\n",
    "plot_hls_results(dse_hls_results, 'FF', xscale_log=True)\n",
    "plot_hls_results(dse_hls_results, 'LUT', xscale_log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save DSE results on file for future reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json = json.dumps(dse_hls_results.copy())\n",
    "f = open(\"dse_hls_results.json\",\"w\")\n",
    "f.write(json)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load DSE results from file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open('dse_hls_results.json') as json_file: \n",
    "    data = json.load(json_file) \n",
    "  \n",
    "    # Print the type of data variable \n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "- Use `Pool` Python package to allocate a number of jobs non bigger than the number of CPU cores/threads similarly to the `-j` option in [GNU Parallel](https://www.gnu.org/software/parallel).\n",
    "- DSE at the same time over `Precision` and `ReuseFactor`.\n",
    "- 3D plotting (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
